{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dot_general requires contracting dimensions to have the same shape, got (32,) and (256,).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 157\u001B[0m\n\u001B[1;32m    154\u001B[0m decoder_batch \u001B[38;5;241m=\u001B[39m shakespeare_indices[batch_start \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m:batch_start \u001B[38;5;241m+\u001B[39m batch_size \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m    155\u001B[0m targets_batch \u001B[38;5;241m=\u001B[39m shakespeare_indices[batch_start \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m2\u001B[39m:batch_start \u001B[38;5;241m+\u001B[39m batch_size \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m2\u001B[39m]\n\u001B[0;32m--> 157\u001B[0m params, loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoder_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecoder_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtargets_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    158\u001B[0m \u001B[38;5;66;03m# Optionally log/print\u001B[39;00m\n",
      "    \u001B[0;31m[... skipping hidden 12 frame]\u001B[0m\n",
      "Cell \u001B[0;32mIn[5], line 126\u001B[0m, in \u001B[0;36mtrain_step\u001B[0;34m(params, encoder_inputs, decoder_inputs, targets)\u001B[0m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;129m@jit\u001B[39m\n\u001B[1;32m    125\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_step\u001B[39m(params, encoder_inputs, decoder_inputs, targets):\n\u001B[0;32m--> 126\u001B[0m     logits \u001B[38;5;241m=\u001B[39m \u001B[43mtransformer_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mencoder_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecoder_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    127\u001B[0m     targets_one_hot \u001B[38;5;241m=\u001B[39m jax\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mone_hot(targets, vocab_size)\n\u001B[1;32m    128\u001B[0m     loss \u001B[38;5;241m=\u001B[39m cross_entropy_loss(logits, targets_one_hot)\n",
      "Cell \u001B[0;32mIn[5], line 98\u001B[0m, in \u001B[0;36mtransformer_model\u001B[0;34m(encoder_inputs, decoder_inputs, params)\u001B[0m\n\u001B[1;32m     95\u001B[0m decoder_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m  \u001B[38;5;66;03m# Optional: Add mask for future tokens\u001B[39;00m\n\u001B[1;32m     97\u001B[0m \u001B[38;5;66;03m# Embedding\u001B[39;00m\n\u001B[0;32m---> 98\u001B[0m encoder_embedding \u001B[38;5;241m=\u001B[39m \u001B[43mjnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mencoder_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43membed_weights\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     99\u001B[0m decoder_embedding \u001B[38;5;241m=\u001B[39m jnp\u001B[38;5;241m.\u001B[39mdot(decoder_inputs, params[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124membed_weights\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m    101\u001B[0m \u001B[38;5;66;03m# Positional Encoding\u001B[39;00m\n",
      "    \u001B[0;31m[... skipping hidden 12 frame]\u001B[0m\n",
      "File \u001B[0;32m~/Documents/nlp-jax/nlp/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:3288\u001B[0m, in \u001B[0;36mdot\u001B[0;34m(a, b, precision, preferred_element_type)\u001B[0m\n\u001B[1;32m   3286\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   3287\u001B[0m     contract_dims \u001B[38;5;241m=\u001B[39m ((a_ndim \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m,), (b_ndim \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m2\u001B[39m,))\n\u001B[0;32m-> 3288\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[43mlax\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot_general\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdimension_numbers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcontract_dims\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_dims\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3289\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mprecision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprecision\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreferred_element_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpreferred_element_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3290\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m lax_internal\u001B[38;5;241m.\u001B[39m_convert_element_type(result, preferred_element_type, output_weak_type)\n",
      "    \u001B[0;31m[... skipping hidden 7 frame]\u001B[0m\n",
      "File \u001B[0;32m~/Documents/nlp-jax/nlp/lib/python3.10/site-packages/jax/_src/lax/lax.py:2580\u001B[0m, in \u001B[0;36m_dot_general_shape_rule\u001B[0;34m(lhs, rhs, dimension_numbers, precision, preferred_element_type)\u001B[0m\n\u001B[1;32m   2577\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m core\u001B[38;5;241m.\u001B[39mdefinitely_equal_shape(lhs_contracting_shape, rhs_contracting_shape):\n\u001B[1;32m   2578\u001B[0m   msg \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdot_general requires contracting dimensions to have the same \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2579\u001B[0m          \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshape, got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m and \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 2580\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg\u001B[38;5;241m.\u001B[39mformat(lhs_contracting_shape, rhs_contracting_shape))\n\u001B[1;32m   2582\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _dot_general_shape_computation(lhs\u001B[38;5;241m.\u001B[39mshape, rhs\u001B[38;5;241m.\u001B[39mshape, dimension_numbers)\n",
      "\u001B[0;31mTypeError\u001B[0m: dot_general requires contracting dimensions to have the same shape, got (32,) and (256,)."
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, grad, jit\n",
    "import optax\n",
    "\n",
    "# Configuration\n",
    "max_len = 50\n",
    "vocab_size = 256\n",
    "hidden_size = 256\n",
    "num_heads = 4\n",
    "num_layers = 2\n",
    "batch_size = 32\n",
    "learning_rate = 3e-4\n",
    "num_epochs = 10\n",
    "\n",
    "# Load Shakespeare dataset from a local text file\n",
    "def load_shakespeare_dataset(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "    return text\n",
    "\n",
    "# Preprocess text data\n",
    "def preprocess_text(text, vocab_size):\n",
    "    vocab = sorted(set(text))\n",
    "    char_to_idx = {char: idx for idx, char in enumerate(vocab)}\n",
    "    idx_to_char = {idx: char for idx, char in enumerate(vocab)}\n",
    "\n",
    "    text_indices = jnp.array([char_to_idx[char] for char in text], dtype=jnp.int32)\n",
    "    return text_indices, char_to_idx, idx_to_char\n",
    "\n",
    "# Positional encoding\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rates = 1 / jnp.power(10000, (2.0 / d_model) * jnp.arange(0, d_model, 2))\n",
    "    angle_rads = (position[:, jnp.newaxis] * angle_rates[jnp.newaxis, :])\n",
    "    sines = jnp.sin(angle_rads)\n",
    "    cosines = jnp.cos(angle_rads)\n",
    "    pos_encoding = jnp.stack([sines, cosines], axis=-1)\n",
    "    pos_encoding = pos_encoding.reshape((position.shape[0], -1))\n",
    "    return pos_encoding\n",
    "\n",
    "# Dot product attention\n",
    "def dot_product_attention(Q, K, V, mask=None):\n",
    "    key_dim = Q.shape[-1]\n",
    "    Q = Q / jnp.sqrt(key_dim)\n",
    "\n",
    "    unnormalized_logits = jnp.einsum('...qd,...kd->...qk', Q, K)\n",
    "\n",
    "    if mask is not None:\n",
    "        unnormalized_logits = jnp.where(mask, unnormalized_logits, -jnp.inf)\n",
    "\n",
    "    attention_weights = jax.nn.softmax(unnormalized_logits, axis=-1)\n",
    "    output = jnp.einsum('...qk,...kv->...qv', attention_weights, V)  # Adjust dimensions here\n",
    "    return output\n",
    "\n",
    "# Multi-head attention\n",
    "def multihead_attention(Q, K, V, mask=None, num_heads=num_heads):\n",
    "    head_dim = hidden_size // num_heads\n",
    "    Q, K, V = [jax.lax.split(x, num_heads, axis=-1) for x in (Q, K, V)]\n",
    "\n",
    "    output = []\n",
    "    for q, k, v in zip(Q, K, V):\n",
    "        output.append(dot_product_attention(q, k, v, mask))\n",
    "\n",
    "    output = jnp.concatenate(output, axis=-1)\n",
    "    return output\n",
    "\n",
    "\n",
    "# Transformer encoder layer\n",
    "def transformer_encoder_layer(x, weights, mask=None):\n",
    "    q = jnp.dot(x, weights[0])\n",
    "    k = v = x\n",
    "    attention_output = multihead_attention(q, k, v, mask)\n",
    "    x = x + attention_output\n",
    "    x = x + jnp.dot(x, weights[1])\n",
    "    return x\n",
    "\n",
    "# Transformer decoder layer\n",
    "def transformer_decoder_layer(x, encoder_output, weights, mask=None):\n",
    "    q = jnp.dot(x, weights[0])\n",
    "    k = v = x\n",
    "    attention_output = multihead_attention(q, k, v, mask)\n",
    "    x = x + attention_output\n",
    "    x = x + jnp.dot(x, weights[1])\n",
    "    q = x\n",
    "    k = encoder_output\n",
    "    v = encoder_output\n",
    "    attention_output = multihead_attention(q, k, v, mask)\n",
    "    x = x + attention_output\n",
    "    x = x + jnp.dot(x, weights[2])\n",
    "    return x\n",
    "\n",
    "# Transformer model\n",
    "def transformer_model(encoder_inputs, decoder_inputs, params):\n",
    "    encoder_mask = None  # Optional: Add mask for padded values\n",
    "    decoder_mask = None  # Optional: Add mask for future tokens\n",
    "    \n",
    "    # Embedding\n",
    "    encoder_embedding = jnp.dot(encoder_inputs, params['embed_weights'])\n",
    "    decoder_embedding = jnp.dot(decoder_inputs, params['embed_weights'])\n",
    "    \n",
    "    # Positional Encoding\n",
    "    encoder_embedding += params['positional_encodings'][:encoder_inputs.shape[1], :]\n",
    "    decoder_embedding += params['positional_encodings'][:decoder_inputs.shape[1], :]\n",
    "    \n",
    "    # Encoder\n",
    "    for layer_weights in params['encoder_weights']:\n",
    "        encoder_embedding = transformer_encoder_layer(encoder_embedding, layer_weights, encoder_mask)\n",
    "    \n",
    "    # Decoder\n",
    "    for layer_weights in params['decoder_weights']:\n",
    "        decoder_embedding = transformer_decoder_layer(decoder_embedding, encoder_embedding, layer_weights, decoder_mask)\n",
    "    \n",
    "    # Output layer\n",
    "    logits = jnp.dot(decoder_embedding, params['output_weights'])\n",
    "    return logits\n",
    "\n",
    "# Loss function\n",
    "def cross_entropy_loss(logits, targets):\n",
    "    return -jnp.mean(jax.nn.log_softmax(logits) * targets)\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = optax.adam(learning_rate)\n",
    "\n",
    "@jit\n",
    "def train_step(params, encoder_inputs, decoder_inputs, targets):\n",
    "    logits = transformer_model(encoder_inputs, decoder_inputs, params)\n",
    "    targets_one_hot = jax.nn.one_hot(targets, vocab_size)\n",
    "    loss = cross_entropy_loss(logits, targets_one_hot)\n",
    "    grads = grad(loss)(params)\n",
    "    updates, _ = optimizer.update(grads, params)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "    return new_params, loss\n",
    "\n",
    "# Load Shakespeare dataset\n",
    "shakespeare_text = load_shakespeare_dataset('shakespeare.txt')\n",
    "\n",
    "# Preprocess text data\n",
    "shakespeare_indices, char_to_idx, idx_to_char = preprocess_text(shakespeare_text, vocab_size)\n",
    "\n",
    "# Initialize parameters for the Transformer model\n",
    "rng = random.PRNGKey(42)\n",
    "params = {\n",
    "    'embed_weights': random.normal(rng, (vocab_size, hidden_size)),\n",
    "    'positional_encodings': positional_encoding(jnp.arange(max_len), hidden_size),\n",
    "    'encoder_weights': [random.normal(rng, (hidden_size, hidden_size)) for _ in range(num_layers)],\n",
    "    'decoder_weights': [random.normal(rng, (hidden_size, hidden_size)) for _ in range(num_layers)],\n",
    "    'output_weights': random.normal(rng, (hidden_size, vocab_size)),\n",
    "}\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_start in range(0, len(shakespeare_indices) - max_len, batch_size):\n",
    "        encoder_batch = shakespeare_indices[batch_start:batch_start + batch_size]\n",
    "        decoder_batch = shakespeare_indices[batch_start + 1:batch_start + batch_size + 1]\n",
    "        targets_batch = shakespeare_indices[batch_start + 2:batch_start + batch_size + 2]\n",
    "\n",
    "        params, loss = train_step(params, encoder_batch, decoder_batch, targets_batch)\n",
    "        # Optionally log/print\n"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-01T23:29:27.365636638Z",
     "start_time": "2024-01-01T23:29:26.590578132Z"
    }
   },
   "id": "initial_id",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-01T23:29:27.367199592Z"
    }
   },
   "id": "d0a6496b4f299ea7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
